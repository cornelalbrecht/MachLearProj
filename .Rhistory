chart_Series(dat])
chart_Series(dat)
chartSeries(dat)
chartSeries(dat["2015"])
chartSeries(dat["2015:2016"])
chartSeries(dat["2015-2016"])
chartSeries(dat["2015"])
chartSeries(dat["2016"])
chartSeries(dat["2015":2016"])
chartSeries(dat["2015":"2016"])
chartSeries(dat["2015:2016"])
chartSeries(dat["2015"])
chartSeries(dat["2016"])
a <- .0168213
rm(dat)
dat <- Quandl("YAHOO/DE_ADV")
View(dat)
dailyReturn
periodReturn
Cl(dat)
?Cl
library(PerformanceAnalytics)
for (i in 1:nrow(dat)){
print((dat$`Adjusted Close`[i] - dat$`Adjusted Close`[i-1].))
for (i in 1:nrow(dat)){
print((dat$`Adjusted Close`[i] - dat$`Adjusted Close`[i+1]))
}
for (i in 1:nrow(dat)-1){
print((dat$`Adjusted Close`[i] - dat$`Adjusted Close`[i+1])/dat$`Adjusted Close`[i-1])
}
ret  <- vector()
for (i in 1:nrow(dat)-1){
ret[i] <- ((dat$`Adjusted Close`[i] - dat$`Adjusted Close`[i+1])/dat$`Adjusted Close`[i-1])
}
ret
ret  <- vector()
for (i in 1:nrow(dat)-1){
ret[i] <- ((dat$`Adjusted Close`[i] - dat$`Adjusted Close`[i+1])/dat$`Adjusted Close`[i+1])
}
SortinoRatio(ret)
?Quandl
library(Quandl)
?Quandl
dat <- Quandl("YAHOO/DE_ADV.4")
View(dat)
dat <- Quandl("YAHOO/DE_ADV", column_index = 4)
dat <- Quandl("YAHOO/DE_ADV", column_index = 6)
View(dat)
dat <- Quandl("YAHOO/DE_ADV", column_index = 7)
dat <- Quandl("YAHOO/DE_ADV", column_index = 6, transform = "rdiff")
View(dat)
dat <- Quandl("YAHOO/DE_ADV",transform = "rdiff")
dat <- Quandl("YAHOO/DE_ADV",transform = "nromalize")
dat <- Quandl("YAHOO/DE_ADV",transform = "normalize")
dat <- Quandl("YAHOO/DE_ADV",transform = "rdiff")
dat <- Quandl("YAHOO/DE_ADV",transform = "diff")
SortinoRatio(dat$`Adjusted Close`)
dat <- Quandl("YAHOO/DE_ADV",transform = "diff", dataset_code = T)
View(dat)
mydata = Quandl(c("NSE/OIL.4","WIKI/AAPL.1"))
View(mydata)
Quandl.search("Oil")
dat <- Quandl("YAHOO/DE_ADV",transform = "diff", limit = 5)
View(dat)
dat <- Quandl("YAHOO/DE_ADV",transform = "diff", limit = 5, collapse = "annual")
View(dat)
dat <- Quandl("YAHOO/DE_ADV",transform = "rdiff", limit = 5, collapse = "annual")
View(dat)
dat <- Quandl("YAHOO/DE_ADV",transform = "rdiff", limit = 10, collapse = "annual")
View(dat)
library(quantmod)
annualReturn(dat$`Adjusted Close`)
install.packages("devtools")
library(devtools)
install_github('quandl/R-package')
library(Quandl)
install.packages(c("BH", "forecast", "ggplot2", "Hmisc", "knitr", "latticeExtra", "lme4", "memoise", "mgcv", "munsell", "nlme", "nnet", "quantreg", "Rcpp", "rJava", "rstudioapi", "testthat", "timeSeries", "withr", "xtable"))
shiny::runApp()
q()
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
modFi <- train(TotalIntench2 ~ FiberWidthCh1 + PerimStatusCh1, method = "rpart", data = segmentationOriginal)
modFi <- train(Case ~ TotalIntench2 + FiberWidthCh1 + PerimStatusCh1, method = "rpart", data = segmentationOriginal)
modFi <- train(Case ~ ., method = "rpart", data = segmentationOriginal)
modFi
plot(modFi$finalModel)
plot(modFi$finalModel, uniform = T)
modFi <- train(Case ~ ., method = "rpart", data = segmentationOriginal)
set.seed(125)
modFi <- train(Case ~ ., method = "rpart", data = segmentationOriginal)
modFi$finalModel
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(modFi$finalModel)
fancyRpartPlot(modFi$)
fancyRpartPlot(modFi)
View(segmentationOriginal)
library(dplyr)
test <- segmentationOriginal[segmentationOriginal$Case == "test"]
test <- segmentationOriginal[segmentationOriginal$Case == "Test"]
test <- segmentationOriginal[segmentationOriginal$Case == "Test",]
train <- segmentationOriginal[segmentationOriginal$Case == "Train",]
set.seed(125)
View(segmentationOriginal)
mod <- train(Class ~ ., data = segmentationOriginal, method = "rpart")
plot(mod$finalModel)
mod <- train(Class ~ ., data = train, method = "rpart")
plot(mod$finalModel)
fancyRpartPlot(mod$finalModel)
library(rpart)
fancyRpartPlot(mod$finalModel)
mod <- train(Class ~ ., data = train, method = "rpart")
plot(mod$finalModel)
library(rpart)
library(ggplot2)
library(rattle)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
fancyRpartPlot(model$finalModel)
plot(model)
plot(model$finalModel
)
mod$finalModel
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
test <- segmentationOriginal[segmentationOriginal$Case == "Test",]
train <- segmentationOriginal[segmentationOriginal$Case == "Train",]
set.seed(125)
mod <- train(Class ~ ., data = train, method = "rpart")
plot(mod$finalModel)
mod$finalModel
library(rattle)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
library(pgmm)
data(olive)
olive = olive[,-1]
library(pgmm)
data(olive)
olive = olive[,-1]
library(caret)
mod <- train(Area ~., data = olive, method = "rpart")
View(olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(mod, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(SAheart)
str(SAheart)
set.seed(13234)
mod <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
library(caret)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
mod <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
pred <- predict(mod, testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, pred)
missClass(trainSA$chd, mod$pred)
missClass(trainSA$chd, mod$pred)
mode$pred
mod$pred
mod$bestTune
predtrain <- predict(mod, trainSA)
missClass(trainSA$chd, predtrain)
missClass(testSA$chd, pred)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
mod <- train(y~., data = vowel.train, method = "rf")
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
mod <- train(y~., data = vowel.train, method = "rf")
mod <- train(y~., data = vowel.train, method = "rf", importance = F)
str(vowel.train)
vowel.train$y <- as.factor(vowel.train)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train)
mod <- train(y~., data = vowel.train, method = "rf", importance = F)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
# The order of the variables is:
#  x.2, x.1, x.5, x.6, x.8, x.4, x.9, x.3, x.7,x.10
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
mod <- train(y~., data = vowel.train, method = "rf", importance = F)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
# The order of the variables is:
#  x.2, x.1, x.5, x.6, x.8, x.4, x.9, x.3, x.7,x.10
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
modelRf
varImp(modelRf)
sort(varImp(modelRf))
order(varImp(modelRf))
ord <- order(varImp(modelRf))
modelRf[ord]
modelRf
varImp(modelRf)
duh <- varImp(modelRf)
duh
library(dplyr)
arrage(duh)
arrange(duh)
duh
sort(duh)
order(duh)
duh[order(duh)]
duh[order(duh),]
modelRf$importance
order(modelRf$importance)
q()
data(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl)
m <- lm(mpg ~ wt + cyl, data = mtcars)
summary(mtcars)
summary(m)
m2 <- lm(mpg ~ cyl, data = mtcars)
summary(m2)
m3 <- lm(mpg ~ wt + cyl + wt:cyl, data = mtcars)
summary(m3)
anova(m,m3)
data(mtcars)
m4 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(m4)
?mtcars
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
m5 <- lm(y~x)
hatvalues(m5$residuals)
hatvalues(m5)
max(hatvalues(m5))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
m6 <- lm(y~x)
dfbeta(m6)
max(dfbeta(m6))
hatvalues(m6)
dfbeta(m6)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
m6 <- lm(y~x)
hatvalues(m6)
dfbeta(m6)
?dfbeta
influence.measures(m6)
data(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl)
m <- lm(mpg ~ wt + cyl, data = mtcars)
## 2
m2 <- lm(mpg ~ cyl, data = mtcars)
summary(m)
summary(m2)
q()
q()
library(ElemStatLearn)
data("vowel.train")
data("vowel.test")
librart(Caret)
library(Caret)
library(caret)
set.seed(33833)
rf  <- train(y~., data = vowel.train, method = "rf")
vowel.train$y <- as.factor(voewel.train$y)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
rf  <- train(y~., data = vowel.train, method = "rf")
gbm  <- train(y~., data = vowel.train, method = "gbm")
confusionMatrix(vowel.test$y, predict(rf, vowel.test))
confusionMatrix(vowel.test$y, predict(gbm, vowel.test))
confusionMatrix(predict(gmm, vowel.test), predict(rf, vowel.test))
confusionMatrix(predict(gbm, vowel.test), predict(rf, vowel.test))
a <- predict(gbm, vowel.test)
b <- predict(rf, vowel.test)
a == b
c <- a == b
a[c]
vowel.test$y
confusionMatrix(a[c], vowel.test$y[c])
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
arf <- train(diagnosis ~., data = training, method = "rf")
bgbm <- train(diagnosis ~., data = training, method = "gbm")
clda <- train(diagnosis ~., data = training, method = "lda")
clda <- train(diagnosis ~., data = training, method = "ida")
clda <- train(diagnosis ~., data = training, method = "lda")
clda
pa <- predict(arf, testing)
pb <- predict(bgbm, testing)
pc <- predict(clda, testing)
dcomb <- train(diagnosis~., data = data.frame(pa,pb,pc, testing$diagnosis))
dcomb <- train(diagnosis~., data = data.frame(pa,pb,pc, testing$diagnosis), method = "rf")
pa
pb
pc
testing$diagnosis
dcomb <- train(diagnosis~., data = data.frame(cbind(pa,pb,pc, testing$diagnosis), method = "rf")
)
dcomb <- train(diagnosis~., data = data.frame(cbind(pa,pb,pc, testing$diagnosis)), method = "rf")
length(pa)
length(pb)
length(pc)
dcomb <- train(diagnosis~., data = cbind(pa,pb,pc, testing$diagnosis), method = "rf")
dcomb <- train(diagnosis~., data = cbind(pa,pb,pc, diagnosistesting$diagnosis), method = "rf")
dcomb <- train(diagnosis~., data = cbind(pa,pb,pc, diagnosis = testing$diagnosis), method = "rf")
dcomb
epred <- predict(dcomb)
confusionMatrix(epred, testing$diagnosis)
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)
confusionMatrix(combPred, testing$diagnosis)
confusionMatrix(pred_lda, testing$diagnosis)
confusionMatrix(pred_gbm, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
pred_scv
pred_svm
library(MASS)
head(shuttle)
shuttle2<-shuttle
shuttle2$use2<-as.numeric(shuttle2$use=='auto')
#shuttle2$wind2<-as.numeric(shuttle2$wind=='head')
#head(shuttle2)
fit<-glm(use2 ~ factor(wind) - 1, family = binomial, data = shuttle2)
View(shuttle)
View(shuttle2)
fit
?glm
summary(fit)$coef
exp(coef(fit))
exp(cbind(OddsRatio = coef(fit), confint(fit)))
shuttle$usebin <- as.numeric(shuttle$use == "auto") # create a binary variable
fit <- glm(usebin ~ factor(wind) - 1, family = "binomial", data = shuttle)
Coef <- coef(summary(fit))
coef.odds <- exp(c(Coef[1, 1], Coef[2, 1]))
(odds.ratio <- coef.odds[1] / coef.odds[2]) # "head" is the reference
fit<-glm(use2 ~ factor(wind) + factor(magn) - 1, family = binomial, data = shuttle2)
summary(fit)$coef
fit<-glm(count~factor(spray)-1,data=InsectSprays,family=poisson)
summary(fit)$coef
2.674/2.73
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots <- 0
splineTerms <- sapply(knots, function(knot) (x > knot) * (x - knot))
(xMat <- cbind(1, x, splineTerms))
View(xMat)
(fit6 <- lm(y ~ xMat - 1))
q()
library(randomForest)
?rfcv
setwd("~/Google Drive/DataScienceClasses/Machine Learning")
library(dplyr)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
# Setting seed for reproducibility
set.seed(4711)
if(!file.exists("train.csv")){
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "train.csv", method = "curl")
}
if(!file.exists("test.csv")){
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "test.csv", method = "curl")
}
train <- read.csv("train.csv", na.strings = c("","NA","#DIV/0!"))
test <- read.csv("test.csv", na.strings = c("","NA","#DIV/0!"))
# This takes care of the NA colums
remove <- apply(train, 2, function(x){mean(is.na(x))})
#levels(factor(removeNA))
remove <- remove > 0.9
# This takes care of the first 7 colums
remove[1:7] = TRUE
# Get rid of colums in test and training data
train <- train[,!remove]
test <- test[,!remove]
insamp <- createDataPartition(train$classe, p = 0.65, list = FALSE)
insTrain <- train[insamp, ]
outTrain <- train[-insamp, ]
RFfit <- randomForest(classe ~ ., data = insTrain, do.trace = F)
varImpPlot(RFfit)
# Random Forest
confusionMatrix(outTrain$classe, predict(RFfit, outTrain))
cvres <- rfcv(trainx = insTrain[,1:52], trainy = insTrain$classe, cv.fold = 5)
cvres <- rfcv(trainx = insTrain[,1:52], trainy = insTrain$classe, cv.fold = 3)
with(cvres, plot(n.var, error.cv, log="x", type="o", lwd=2))
cvres$error.cv
cvres$n.var
q()
